{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd5a8e7-76d0-4d19-a857-b6eb4fbf3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neomodel import db, config\n",
    "\n",
    "# Neomodel connection\n",
    "config.DATABASE_NAME = 'version1'\n",
    "db.set_connection(url='bolt://neo4j:12345678@localhost:7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be5145c-298c-4f2f-b544-403c8cafd4b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mcypher_query(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch (n1_annotation:Class)-[a1:ANNOTATES \u001b[39m\u001b[38;5;132;01m{level: 0}\u001b[39;00m\u001b[38;5;124m]-(n1:Reviewed)-[r:COMPARED]-(n2:Reviewed)-[a2:ANNOTATES \u001b[39m\u001b[38;5;132;01m{level: 0}\u001b[39;00m\u001b[38;5;124m]-(n2_annotation:Class) return n1.text,n2.text,r.label,n1_annotation.text,n1_annotation.definition,n2_annotation.text,n2_annotation.definition\u001b[39m\u001b[38;5;124m\"\u001b[39m);\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mtype\u001b[39m(results),\u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "results = db.cypher_query(\"match (n1_annotation:Class)-[a1:ANNOTATES {level: 0}]-(n1:Reviewed)-[r:COMPARED]-(n2:Reviewed)-[a2:ANNOTATES {level: 0}]-(n2_annotation:Class) return n1.text,n2.text,r.label,n1_annotation.text,n1_annotation.definition,n2_annotation.text,n2_annotation.definition\");\n",
    "type(results),len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7767b862-e1a6-42d9-ae18-74ce77b5dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results[0],columns=results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd812f73-bd95-4c5c-8130-0eb9aab7ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.drop_duplicates() # TODO: find out about duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5007e32a-2427-4fce-8e81-396211002f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1.text</th>\n",
       "      <th>n2.text</th>\n",
       "      <th>r.label</th>\n",
       "      <th>n1_annotation.text</th>\n",
       "      <th>n1_annotation.definition</th>\n",
       "      <th>n2_annotation.text</th>\n",
       "      <th>n2_annotation.definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>NM</td>\n",
       "      <td>Body Image</td>\n",
       "      <td>No definition</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>NM</td>\n",
       "      <td>Body</td>\n",
       "      <td>The entire physical structure of an organism. ...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>NM</td>\n",
       "      <td>Body of Stomach</td>\n",
       "      <td>The main section of the digestive tube that co...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>NM</td>\n",
       "      <td>Document Body</td>\n",
       "      <td>The central message of a communication.</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>NM</td>\n",
       "      <td>Body of the Pancreas</td>\n",
       "      <td>The part of the pancreas from the point where ...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 n1.text           n2.text r.label    n1_annotation.text  \\\n",
       "0  body image disruption  Mood disturbance      NM            Body Image   \n",
       "1  body image disruption  Mood disturbance      NM                  Body   \n",
       "2  body image disruption  Mood disturbance      NM       Body of Stomach   \n",
       "3  body image disruption  Mood disturbance      NM         Document Body   \n",
       "4  body image disruption  Mood disturbance      NM  Body of the Pancreas   \n",
       "\n",
       "                            n1_annotation.definition  \\\n",
       "0                                      No definition   \n",
       "1  The entire physical structure of an organism. ...   \n",
       "2  The main section of the digestive tube that co...   \n",
       "3            The central message of a communication.   \n",
       "4  The part of the pancreas from the point where ...   \n",
       "\n",
       "              n2_annotation.text  \\\n",
       "0  Symptoms Interfered with Mood   \n",
       "1  Symptoms Interfered with Mood   \n",
       "2  Symptoms Interfered with Mood   \n",
       "3  Symptoms Interfered with Mood   \n",
       "4  Symptoms Interfered with Mood   \n",
       "\n",
       "                            n2_annotation.definition  \n",
       "0  A question about how much an individuals sympt...  \n",
       "1  A question about how much an individuals sympt...  \n",
       "2  A question about how much an individuals sympt...  \n",
       "3  A question about how much an individuals sympt...  \n",
       "4  A question about how much an individuals sympt...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d14f5cc-1be4-46c4-b31b-a1d6fa01a7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r.label\n",
       "0.0        26008\n",
       "NM         19656\n",
       "M           6521\n",
       "L           6178\n",
       "0.25        4874\n",
       "S           4730\n",
       "0.75        2048\n",
       "1.0         1959\n",
       "0.5         1734\n",
       "O            530\n",
       "O and L       14\n",
       "L or S        10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['r.label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1052802c-fe71-4ab2-b8a1-5173405e9610",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.loc[results_df['r.label'].isin([0.0,0.25,0.5,0.75,1.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e425f248-855b-48d3-81f3-0bb0840b87f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36623, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db4206f-efc5-4e86-ad77-fff2b81c6a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36623, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1aee9-0ef2-4150-92cd-f02a04acc1b0",
   "metadata": {},
   "source": [
    "# Generate embeddings for the entities and the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45532f1c-6a85-40f1-8ce4-edcb7b5e0d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "model = AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "#turned off real comparison for now\n",
    "\n",
    "def entity_sim(entity):\n",
    "    entityA = entity[\"n1.text\"]\n",
    "    entityB = entity[\"n2.text\"]\n",
    "    return float(entityA == entityB)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tokenA = tokenizer(entityA, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        tokenB = tokenizer(entityB, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        embA = model(**tokenA).last_hidden_state.mean(dim=1)\n",
    "        embB = model(**tokenB).last_hidden_state.mean(dim=1)\n",
    "        return torch.nn.functional.cosine_similarity(embA, embB).item()\n",
    "\n",
    "def annotation_sim(entity):\n",
    "    sentA = entity[\"n1_annotation.text\"]\n",
    "    sentB = entity[\"n2_annotation.text\"]\n",
    "    return float(sentA == sentB)\n",
    "    with torch.no_grad():\n",
    "        tokenA = tokenizer(sentA, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        tokenB = tokenizer(sentB, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        embA = model(**tokenA).last_hidden_state.mean(dim=1)\n",
    "        embB = model(**tokenB).last_hidden_state.mean(dim=1)\n",
    "        return torch.nn.functional.cosine_similarity(embA, embB).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2859522-e612-4649-8d4f-e3cac748ce0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "542eee18-a708-4793-b861-c7f24a8ef67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1.text</th>\n",
       "      <th>n2.text</th>\n",
       "      <th>r.label</th>\n",
       "      <th>n1_annotation.text</th>\n",
       "      <th>n1_annotation.definition</th>\n",
       "      <th>n2_annotation.text</th>\n",
       "      <th>n2_annotation.definition</th>\n",
       "      <th>Entity Similarity</th>\n",
       "      <th>Annotation Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Adverse Event Associated with Pain</td>\n",
       "      <td>No definition</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pain</td>\n",
       "      <td>The sensation of discomfort, distress, or agon...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pain by Anatomic Descriptor, CTCAE</td>\n",
       "      <td>No definition</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feel Pain</td>\n",
       "      <td>A question about whether an individual feels o...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pain Distress</td>\n",
       "      <td>A question about the intensity of an individua...</td>\n",
       "      <td>Symptoms Interfered with Mood</td>\n",
       "      <td>A question about how much an individuals sympt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506413</th>\n",
       "      <td>cognitive impairment</td>\n",
       "      <td>depressive symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cognitive</td>\n",
       "      <td>Of or being or relating to or involving cognit...</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>Exhibiting the symptoms of a particular disease.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506414</th>\n",
       "      <td>cognitive impairment</td>\n",
       "      <td>depressive symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Impairment</td>\n",
       "      <td>Loss or abnormality of psychological, physiolo...</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>Exhibiting the symptoms of a particular disease.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506424</th>\n",
       "      <td>cognitive impairment</td>\n",
       "      <td>depressive symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cognitive Impairment</td>\n",
       "      <td>Diminished mental function.</td>\n",
       "      <td>Rheumatic Fever Symptom</td>\n",
       "      <td>The symptoms of rheumatic fever that the patie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506425</th>\n",
       "      <td>cognitive impairment</td>\n",
       "      <td>depressive symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cognitive</td>\n",
       "      <td>Of or being or relating to or involving cognit...</td>\n",
       "      <td>Rheumatic Fever Symptom</td>\n",
       "      <td>The symptoms of rheumatic fever that the patie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506426</th>\n",
       "      <td>cognitive impairment</td>\n",
       "      <td>depressive symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Impairment</td>\n",
       "      <td>Loss or abnormality of psychological, physiolo...</td>\n",
       "      <td>Rheumatic Fever Symptom</td>\n",
       "      <td>The symptoms of rheumatic fever that the patie...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36623 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     n1.text              n2.text r.label  \\\n",
       "10                      pain     Mood disturbance     0.0   \n",
       "11                      pain     Mood disturbance     0.0   \n",
       "12                      pain     Mood disturbance     0.0   \n",
       "13                      pain     Mood disturbance     0.0   \n",
       "14                      pain     Mood disturbance     0.0   \n",
       "...                      ...                  ...     ...   \n",
       "506413  cognitive impairment  depressive symptoms     0.0   \n",
       "506414  cognitive impairment  depressive symptoms     0.0   \n",
       "506424  cognitive impairment  depressive symptoms     0.0   \n",
       "506425  cognitive impairment  depressive symptoms     0.0   \n",
       "506426  cognitive impairment  depressive symptoms     0.0   \n",
       "\n",
       "                        n1_annotation.text  \\\n",
       "10      Adverse Event Associated with Pain   \n",
       "11                                    Pain   \n",
       "12      Pain by Anatomic Descriptor, CTCAE   \n",
       "13                               Feel Pain   \n",
       "14                           Pain Distress   \n",
       "...                                    ...   \n",
       "506413                           Cognitive   \n",
       "506414                          Impairment   \n",
       "506424                Cognitive Impairment   \n",
       "506425                           Cognitive   \n",
       "506426                          Impairment   \n",
       "\n",
       "                                 n1_annotation.definition  \\\n",
       "10                                          No definition   \n",
       "11      The sensation of discomfort, distress, or agon...   \n",
       "12                                          No definition   \n",
       "13      A question about whether an individual feels o...   \n",
       "14      A question about the intensity of an individua...   \n",
       "...                                                   ...   \n",
       "506413  Of or being or relating to or involving cognit...   \n",
       "506414  Loss or abnormality of psychological, physiolo...   \n",
       "506424                        Diminished mental function.   \n",
       "506425  Of or being or relating to or involving cognit...   \n",
       "506426  Loss or abnormality of psychological, physiolo...   \n",
       "\n",
       "                   n2_annotation.text  \\\n",
       "10      Symptoms Interfered with Mood   \n",
       "11      Symptoms Interfered with Mood   \n",
       "12      Symptoms Interfered with Mood   \n",
       "13      Symptoms Interfered with Mood   \n",
       "14      Symptoms Interfered with Mood   \n",
       "...                               ...   \n",
       "506413                    Symptomatic   \n",
       "506414                    Symptomatic   \n",
       "506424        Rheumatic Fever Symptom   \n",
       "506425        Rheumatic Fever Symptom   \n",
       "506426        Rheumatic Fever Symptom   \n",
       "\n",
       "                                 n2_annotation.definition  Entity Similarity  \\\n",
       "10      A question about how much an individuals sympt...                0.0   \n",
       "11      A question about how much an individuals sympt...                0.0   \n",
       "12      A question about how much an individuals sympt...                0.0   \n",
       "13      A question about how much an individuals sympt...                0.0   \n",
       "14      A question about how much an individuals sympt...                0.0   \n",
       "...                                                   ...                ...   \n",
       "506413   Exhibiting the symptoms of a particular disease.                0.0   \n",
       "506414   Exhibiting the symptoms of a particular disease.                0.0   \n",
       "506424  The symptoms of rheumatic fever that the patie...                0.0   \n",
       "506425  The symptoms of rheumatic fever that the patie...                0.0   \n",
       "506426  The symptoms of rheumatic fever that the patie...                0.0   \n",
       "\n",
       "        Annotation Similarity  \n",
       "10                        0.0  \n",
       "11                        0.0  \n",
       "12                        0.0  \n",
       "13                        0.0  \n",
       "14                        0.0  \n",
       "...                       ...  \n",
       "506413                    0.0  \n",
       "506414                    0.0  \n",
       "506424                    0.0  \n",
       "506425                    0.0  \n",
       "506426                    0.0  \n",
       "\n",
       "[36623 rows x 9 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = results_df.copy()\n",
    "labeled_data[\"Entity Similarity\"] = results_df.apply(entity_sim, axis=1)\n",
    "labeled_data[\"Annotation Similarity\"] = results_df.apply(annotation_sim, axis=1)\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c3a808-a729-4c34-84d7-aa68da20ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "False    34664\n",
       "True      1959\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data['Label'] = labeled_data['r.label'] == 1.0\n",
    "labeled_data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082ac8c-dc02-4353-bf26-8f5a9b48588c",
   "metadata": {},
   "source": [
    "results = db.cypher_query(\"match (n1:Reviewed)-[r:COMPARED]-(n2:Reviewed) with n1,r,n2 OPTIONAL MATCH (n1)-[r2:SIM_ANNOTATION]-(n2) return n1.text,n2.text,r.label,ID(r2)\")\n",
    "test_results = pd.DataFrame(results[0],columns=results[1])\n",
    "test_results['Test Prediction'] = test_results['ID(r2)'].isna()==False\n",
    "print(classification_report(test_results['r.label'],test_results['Test Prediction'].map({True:'M',False:'NM'})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2959662b-c74f-47b4-bc3e-c2dd7c32032b",
   "metadata": {},
   "source": [
    "X = labeled_data[['Entity Similarity','Annotation Similarity']]\n",
    "y = labeled_data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10dc90-cece-480b-b151-eec33947cf89",
   "metadata": {},
   "source": [
    "labeled_data.loc[labeled_data['Annotation Similarity'] == 1]['r.label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1e690-4271-4822-a3cb-b4ed1e2124d8",
   "metadata": {},
   "source": [
    "labeled_data.loc[labeled_data['Annotation Similarity'] == 1][['r.label','Entity Similarity']].sort_values(by='r.label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891e1ad0-5b8b-4e51-9f09-3253171dd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH (a1:Reviewed)-[r1:ANNOTATES]-(c:Class)-[r2:ANNOTATES]-(a2:Reviewed) WITH a1,a2,count(c) as n MERGE (a1)-[r3:SHARED_ANNOTATION {n:n}]-(a2) return *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d5e962c-105d-4ee0-8759-95491127119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data['Same annotation'] = 1.0*(labeled_data['Annotation Similarity'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8e3248ee-0dd9-44a4-8f85-c985c9d1274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = labeled_data.groupby(['n1.text','n2.text'])['Same annotation'].sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab63b797-c660-4e56-af1d-24866ddeeb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>num_annotations_common</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1.text</th>\n",
       "      <th>n2.text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">stress</th>\n",
       "      <th>pain</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symptom</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride length</th>\n",
       "      <th>stride time</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stride time</th>\n",
       "      <th>stride length</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symptom</th>\n",
       "      <th>fatigue</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain interference</th>\n",
       "      <th>pain</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain intensity</th>\n",
       "      <th>pain</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">pain</th>\n",
       "      <th>pain interference</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain intensity</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pain</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     num_annotations_common\n",
       "n1.text           n2.text                                  \n",
       "stress            pain                                  0.0\n",
       "                  symptom                               0.0\n",
       "stride length     stride time                           0.0\n",
       "stride time       stride length                         0.0\n",
       "symptom           fatigue                               0.0\n",
       "...                                                     ...\n",
       "pain interference pain                                 30.0\n",
       "pain intensity    pain                                 30.0\n",
       "pain              pain interference                    30.0\n",
       "                  pain intensity                       30.0\n",
       "                  pain                                 40.0\n",
       "\n",
       "[477 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df = labeled_data.groupby(['n1.text','n2.text'])['Same annotation'].sum().sort_values().to_frame()\n",
    "counts_df.columns=['num_annotations_common']\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ad9d08de-9cd2-4791-a760-5c559ca9d28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-a9a07cd742804f98b6ee9aefa4a04753.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-a9a07cd742804f98b6ee9aefa4a04753.vega-embed details,\n",
       "  #altair-viz-a9a07cd742804f98b6ee9aefa4a04753.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-a9a07cd742804f98b6ee9aefa4a04753\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-a9a07cd742804f98b6ee9aefa4a04753\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-a9a07cd742804f98b6ee9aefa4a04753\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d16d525281c4fdedbd3ac3b93ecd3768\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"bin\": true, \"field\": \"num_annotations_common\", \"title\": \"Number of annotations in common\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-d16d525281c4fdedbd3ac3b93ecd3768\": [{\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 0.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 1.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 2.0}, {\"num_annotations_common\": 3.0}, {\"num_annotations_common\": 3.0}, {\"num_annotations_common\": 3.0}, {\"num_annotations_common\": 3.0}, {\"num_annotations_common\": 4.0}, {\"num_annotations_common\": 4.0}, {\"num_annotations_common\": 4.0}, {\"num_annotations_common\": 4.0}, {\"num_annotations_common\": 5.0}, {\"num_annotations_common\": 5.0}, {\"num_annotations_common\": 5.0}, {\"num_annotations_common\": 5.0}, {\"num_annotations_common\": 6.0}, {\"num_annotations_common\": 6.0}, {\"num_annotations_common\": 6.0}, {\"num_annotations_common\": 6.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 10.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 11.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 12.0}, {\"num_annotations_common\": 14.0}, {\"num_annotations_common\": 14.0}, {\"num_annotations_common\": 15.0}, {\"num_annotations_common\": 15.0}, {\"num_annotations_common\": 18.0}, {\"num_annotations_common\": 18.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 20.0}, {\"num_annotations_common\": 22.0}, {\"num_annotations_common\": 22.0}, {\"num_annotations_common\": 24.0}, {\"num_annotations_common\": 24.0}, {\"num_annotations_common\": 30.0}, {\"num_annotations_common\": 30.0}, {\"num_annotations_common\": 30.0}, {\"num_annotations_common\": 30.0}, {\"num_annotations_common\": 40.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(counts_df.set_index(np.arange(len(counts_df)))).mark_bar().encode(\n",
    "    alt.X(\"num_annotations_common:Q\", bin=True, title='Number of annotations in common'),\n",
    "    y='count()',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b35d583-7128-4d25-a536-b10d9e386027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# TODO: not hard code\n",
    "openai.api_key = open(\"/mnt/clbp/.openai_api_key.txt\").read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e7d1914-08cb-4abc-a1ef-68126f5ac04a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_same_openai(term1,term2):\n",
    "    PROMPT = \"You are an biomedical expert. Do the following mean the same thing? Your response should be yes or no with no extra information.\"\n",
    "            \n",
    "    max_tokens = 4097\n",
    "    relevant_paragraphs = []\n",
    "    non_relevant_paragraphs = []\n",
    "    messages=[\n",
    "          {\"role\": \"system\", \"content\": PROMPT},\n",
    "          {\"role\": \"user\", \"content\": \"1. %s\\n2. %s\"%(term1,term2) }\n",
    "    ]\n",
    "    finished = False\n",
    "    c = 1\n",
    "    while not finished:\n",
    "        if c > 3:\n",
    "            break\n",
    "        if c > 1:\n",
    "            print(f\"Trying openai for {c} time\")\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=messages,\n",
    "              temperature=0,\n",
    "              top_p=1,\n",
    "              frequency_penalty=0,\n",
    "              presence_penalty=0\n",
    "            )\n",
    "            finished = True\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        c += 1\n",
    "    \n",
    "    if finished:\n",
    "        response = response['choices'][0]['message']['content'].strip()\n",
    "        return response.lower()=='yes'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "is_same_openai(\"pain\",\"pain options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7811884c-c3fb-412b-9486-eb2e2a5b6efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data.set_index(['n1.text','n2.text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0d00aad-454d-4dc9-8291-a2bd935591a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daf45732-c817-471b-816e-ae6eed97db65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/3837158051.py:5: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  labeled_data.loc[(term1,term2),\"GPT Based Prediction\"] = float(is_same_openai(term1,term2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value.\",\n",
      "        \"type\": \"internal_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"request_timeout\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value.', 'type': 'internal_error', 'param': None, 'code': 'request_timeout'}} {'Date': 'Mon, 26 Feb 2024 00:26:58 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '251', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_7f16a6d1a5d9507b0519b8fb7e5154a6', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '85b4009f3ad0f9e0-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "Trying openai for 2 time\n",
      "Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value. {\n",
      "    \"error\": {\n",
      "        \"message\": \"Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value.\",\n",
      "        \"type\": \"internal_error\",\n",
      "        \"param\": null,\n",
      "        \"code\": \"request_timeout\"\n",
      "    }\n",
      "}\n",
      " 500 {'error': {'message': 'Timed out generating response. Please try again with a shorter prompt or with `max_tokens` set to a lower value.', 'type': 'internal_error', 'param': None, 'code': 'request_timeout'}} {'Date': 'Mon, 26 Feb 2024 00:38:31 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '251', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_de60be45d8641a12a861c2c97b0bd7e9', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '85b4118a3a379878-SJC', 'alt-svc': 'h3=\":443\"; ma=86400'}\n",
      "Trying openai for 2 time\n"
     ]
    }
   ],
   "source": [
    "labeled_data['GPT Based Prediction'] = np.NaN\n",
    "for term1,term2 in np.unique(labeled_data.index):\n",
    "    #term1 = labeled_data.loc[ix,\"n1.text\"]\n",
    "    #term2 = labeled_data.loc[ix,\"n2.text\"]\n",
    "    labeled_data.loc[(term1,term2),\"GPT Based Prediction\"] = float(is_same_openai(term1,term2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa13a8b9-f9b8-412a-8775-e2badaf20699",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5e1ce8b-3102-41d0-bbea-a90762805977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodups_labeled_data = labeled_data[['n1.text','n2.text','GPT Based Prediction','r.label']].drop_duplicates()\n",
    "nodups_labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e29d972-c1d6-495d-9efe-e4b82d383dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "False    398\n",
       "True      27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_report['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1371098-3b7f-4c6b-aa66-35e84931fb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT Based Prediction\n",
       "False    390\n",
       "True      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(for_report['GPT Based Prediction']==1.0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9370af61-6c65-46d8-82c3-8763fe540d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1.text</th>\n",
       "      <th>n2.text</th>\n",
       "      <th>GPT Based Prediction</th>\n",
       "      <th>r.label</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pain</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>body image disruption</td>\n",
       "      <td>Mood disturbance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>spinal pain</td>\n",
       "      <td>Fibromyalgia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>pain interference</td>\n",
       "      <td>somatic symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>pain anxiety</td>\n",
       "      <td>somatic symptoms</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n1.text           n2.text  GPT Based Prediction r.label  \\\n",
       "0                     pain  Mood disturbance                   0.0     0.0   \n",
       "10   body image disruption  Mood disturbance                   0.0     0.0   \n",
       "100            spinal pain      Fibromyalgia                   0.0     0.0   \n",
       "111      pain interference  somatic symptoms                   0.0     0.0   \n",
       "123           pain anxiety  somatic symptoms                   0.0     0.0   \n",
       "\n",
       "     Label  \n",
       "0    False  \n",
       "10   False  \n",
       "100  False  \n",
       "111  False  \n",
       "123  False  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bd4fb5bd-345d-45cb-991b-3af9b44f3089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(for_report['Label'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba932186-54ea-4d7c-9e4e-20a496e00cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(for_report['GPT Based Prediction'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b26839-6df2-463f-ae52-532602580506",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[0;32m----> 2\u001b[0m nodups_labeled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mNaN\n\u001b[1;32m      3\u001b[0m nodups_labeled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[nodups_labeled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr.label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      4\u001b[0m nodups_labeled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[nodups_labeled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr.label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 1.0] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0), output_dict=True)\n",
    "df_1 = pd.DataFrame(report).transpose()\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffe5497e-a38e-4907-85c5-4e65993b1363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.96      0.97       398\n",
      "        True       0.44      0.57      0.50        21\n",
      "\n",
      "    accuracy                           0.94       419\n",
      "   macro avg       0.71      0.77      0.73       419\n",
      "weighted avg       0.95      0.94      0.95       419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/3010906039.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/3010906039.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.969620</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.942721</td>\n",
       "      <td>0.942721</td>\n",
       "      <td>0.942721</td>\n",
       "      <td>0.942721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.710743</td>\n",
       "      <td>0.766870</td>\n",
       "      <td>0.734810</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.950347</td>\n",
       "      <td>0.942721</td>\n",
       "      <td>0.946083</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.977041  0.962312  0.969620  398.000000\n",
       "True           0.444444  0.571429  0.500000   21.000000\n",
       "accuracy       0.942721  0.942721  0.942721    0.942721\n",
       "macro avg      0.710743  0.766870  0.734810  419.000000\n",
       "weighted avg   0.950347  0.942721  0.946083  419.000000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.75] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0), output_dict=True)\n",
    "df_p75 = pd.DataFrame(report).transpose()\n",
    "df_p75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "75717f27-8250-4e38-87d6-9a5d61b48a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.96      0.96       398\n",
      "        True       0.35      0.38      0.36        21\n",
      "\n",
      "    accuracy                           0.93       419\n",
      "   macro avg       0.66      0.67      0.66       419\n",
      "weighted avg       0.94      0.93      0.93       419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/1088565657.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/1088565657.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.967172</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.964736</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.933174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.671632</td>\n",
       "      <td>0.664186</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.936131</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>0.934609</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.967172  0.962312  0.964736  398.000000\n",
       "True           0.347826  0.380952  0.363636   21.000000\n",
       "accuracy       0.933174  0.933174  0.933174    0.933174\n",
       "macro avg      0.657499  0.671632  0.664186  419.000000\n",
       "weighted avg   0.936131  0.933174  0.934609  419.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.50] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0), output_dict=True)\n",
    "df_p5 = pd.DataFrame(report).transpose()\n",
    "df_p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "516e6ae2-29ec-4223-ba91-8135221f4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.96      0.93       398\n",
      "        True       0.38      0.16      0.23        55\n",
      "\n",
      "    accuracy                           0.87       453\n",
      "   macro avg       0.63      0.56      0.58       453\n",
      "weighted avg       0.83      0.87      0.84       453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/699806479.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/699806479.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.892774</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.926239</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>0.227848</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.865342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.633887</td>\n",
       "      <td>0.562974</td>\n",
       "      <td>0.577044</td>\n",
       "      <td>453.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.829910</td>\n",
       "      <td>0.865342</td>\n",
       "      <td>0.841446</td>\n",
       "      <td>453.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.892774  0.962312  0.926239  398.000000\n",
       "True           0.375000  0.163636  0.227848   55.000000\n",
       "accuracy       0.865342  0.865342  0.865342    0.865342\n",
       "macro avg      0.633887  0.562974  0.577044  453.000000\n",
       "weighted avg   0.829910  0.865342  0.841446  453.000000"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.25] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['GPT Based Prediction']==1.0), output_dict=True)\n",
    "df_p25 = pd.DataFrame(report).transpose()\n",
    "df_p25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "52d459bd-e81a-4b95-9488-38046bb68762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">precision</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.892774</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.967172</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.977041</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.982051</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">recall</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.163636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">f1-score</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.926239</td>\n",
       "      <td>0.227848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.964736</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.969620</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.972081</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        False      True\n",
       "          Agreement                    \n",
       "precision 0.25       0.892774  0.375000\n",
       "          0.50       0.967172  0.347826\n",
       "          0.75       0.977041  0.444444\n",
       "          1.00       0.982051  0.571429\n",
       "recall    0.25       0.962312  0.163636\n",
       "          0.50       0.962312  0.380952\n",
       "          0.75       0.962312  0.571429\n",
       "          1.00       0.962312  0.740741\n",
       "f1-score  0.25       0.926239  0.227848\n",
       "          0.50       0.964736  0.363636\n",
       "          0.75       0.969620  0.500000\n",
       "          1.00       0.972081  0.645161"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['Agreement'] = 1.0\n",
    "df_p75['Agreement'] = 0.75\n",
    "df_p5['Agreement'] = 0.5\n",
    "df_p25['Agreement'] = 0.25\n",
    "df = pd.concat((df_1,df_p75,df_p5,df_p25)).drop('support',axis=1)\n",
    "df.loc[['False','True']].pivot(columns='Agreement').transpose()#.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b78dbdd-7790-4990-bfe4-315d2c9bbb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & False & True \\\\\n",
      " & Agreement &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{4}{*}{precision} & 0.250000 & 0.890000 & 0.380000 \\\\\n",
      " & 0.500000 & 0.970000 & 0.350000 \\\\\n",
      " & 0.750000 & 0.980000 & 0.440000 \\\\\n",
      " & 1.000000 & 0.980000 & 0.570000 \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{4}{*}{recall} & 0.250000 & 0.960000 & 0.160000 \\\\\n",
      " & 0.500000 & 0.960000 & 0.380000 \\\\\n",
      " & 0.750000 & 0.960000 & 0.570000 \\\\\n",
      " & 1.000000 & 0.960000 & 0.740000 \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{4}{*}{f1-score} & 0.250000 & 0.930000 & 0.230000 \\\\\n",
      " & 0.500000 & 0.960000 & 0.360000 \\\\\n",
      " & 0.750000 & 0.970000 & 0.500000 \\\\\n",
      " & 1.000000 & 0.970000 & 0.650000 \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((np.round(df.loc[['False','True']].pivot(columns='Agreement').transpose()*100)/100).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "864fa876-41a5-44ec-86df-ab67b9cf4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_ = labeled_data.copy()\n",
    "copy_['Annotation Based Prediction'] = False\n",
    "copy_.set_index(['n1.text','n2.text'],inplace=True)\n",
    "copy_.loc[counts_df.index[counts >= 1],\"Annotation Based Prediction\"] = True #True\n",
    "copy_['Annotation Based Prediction'].value_counts()\n",
    "copy_.reset_index(inplace=True)\n",
    "nodups_labeled_data = copy_[['n1.text','n2.text','Annotation Based Prediction','r.label']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5ca1ddb7-c081-4cb1-9db2-35430ff02022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 4)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodups_labeled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f3e84a45-c499-4256-af04-d4c959a4e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.59      0.74       398\n",
      "        True       0.14      1.00      0.25        27\n",
      "\n",
      "    accuracy                           0.61       425\n",
      "   macro avg       0.57      0.79      0.49       425\n",
      "weighted avg       0.95      0.61      0.71       425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/448239164.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/448239164.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.740506</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.141361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247706</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.614118</td>\n",
       "      <td>0.614118</td>\n",
       "      <td>0.614118</td>\n",
       "      <td>0.614118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.570681</td>\n",
       "      <td>0.793970</td>\n",
       "      <td>0.494106</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.945451</td>\n",
       "      <td>0.614118</td>\n",
       "      <td>0.709199</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          1.000000  0.587940  0.740506  398.000000\n",
       "True           0.141361  1.000000  0.247706   27.000000\n",
       "accuracy       0.614118  0.614118  0.614118    0.614118\n",
       "macro avg      0.570681  0.793970  0.494106  425.000000\n",
       "weighted avg   0.945451  0.614118  0.709199  425.000000"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 1.0] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0), output_dict=True)\n",
    "df_1 = pd.DataFrame(report).transpose()\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "48269186-0207-4f8e-90f3-7a4eb8789b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.59      0.74       398\n",
      "        True       0.10      0.90      0.19        21\n",
      "\n",
      "    accuracy                           0.60       419\n",
      "   macro avg       0.55      0.75      0.46       419\n",
      "weighted avg       0.95      0.60      0.71       419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/736149237.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/736149237.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.738170</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.103825</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.603819</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>0.603819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.547675</td>\n",
       "      <td>0.746351</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.947034</td>\n",
       "      <td>0.603819</td>\n",
       "      <td>0.710510</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.991525  0.587940  0.738170  398.000000\n",
       "True           0.103825  0.904762  0.186275   21.000000\n",
       "accuracy       0.603819  0.603819  0.603819    0.603819\n",
       "macro avg      0.547675  0.746351  0.462222  419.000000\n",
       "weighted avg   0.947034  0.603819  0.710510  419.000000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.75] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0), output_dict=True)\n",
    "df_p75 = pd.DataFrame(report).transpose()\n",
    "df_p75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4b9b25ab-44f7-4fae-977e-7c9c279fb99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.59      0.74       398\n",
      "        True       0.09      0.81      0.17        21\n",
      "\n",
      "    accuracy                           0.60       419\n",
      "   macro avg       0.54      0.70      0.45       419\n",
      "weighted avg       0.94      0.60      0.71       419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/1127991168.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/1127991168.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.093923</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.168317</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.599045</td>\n",
       "      <td>0.599045</td>\n",
       "      <td>0.599045</td>\n",
       "      <td>0.599045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.538558</td>\n",
       "      <td>0.698732</td>\n",
       "      <td>0.452083</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.599045</td>\n",
       "      <td>0.707405</td>\n",
       "      <td>419.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.983193  0.587940  0.735849  398.000000\n",
       "True           0.093923  0.809524  0.168317   21.000000\n",
       "accuracy       0.599045  0.599045  0.599045    0.599045\n",
       "macro avg      0.538558  0.698732  0.452083  419.000000\n",
       "weighted avg   0.938624  0.599045  0.707405  419.000000"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.50] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0), output_dict=True)\n",
    "df_p5 = pd.DataFrame(report).transpose()\n",
    "df_p5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dbbc0b9b-6666-4c71-b210-0a873e4d1ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.59      0.72       398\n",
      "        True       0.20      0.75      0.32        55\n",
      "\n",
      "    accuracy                           0.61       453\n",
      "   macro avg       0.57      0.67      0.52       453\n",
      "weighted avg       0.85      0.61      0.67       453\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37388/1542813978.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
      "/tmp/ipykernel_37388/1542813978.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.724458</td>\n",
       "      <td>398.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.315385</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.607064</td>\n",
       "      <td>0.607064</td>\n",
       "      <td>0.607064</td>\n",
       "      <td>0.607064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.666697</td>\n",
       "      <td>0.519921</td>\n",
       "      <td>453.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.853272</td>\n",
       "      <td>0.607064</td>\n",
       "      <td>0.674791</td>\n",
       "      <td>453.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "False          0.943548  0.587940  0.724458  398.000000\n",
       "True           0.200000  0.745455  0.315385   55.000000\n",
       "accuracy       0.607064  0.607064  0.607064    0.607064\n",
       "macro avg      0.571774  0.666697  0.519921  453.000000\n",
       "weighted avg   0.853272  0.607064  0.674791  453.000000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "nodups_labeled_data['Label'] = np.NaN\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.0] = False\n",
    "nodups_labeled_data['Label'].loc[nodups_labeled_data['r.label'] == 0.25] = True\n",
    "for_report = nodups_labeled_data.copy().dropna()\n",
    "print(classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0)))\n",
    "report = classification_report(list(for_report['Label']), list(for_report['Annotation Based Prediction']==1.0), output_dict=True)\n",
    "df_p25 = pd.DataFrame(report).transpose()\n",
    "df_p25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "35b7c2c7-d987-4fdf-af79-eb85a2e30f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">precision</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.943548</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.093923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.991525</td>\n",
       "      <td>0.103825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">recall</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.745455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.587940</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.587940</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">f1-score</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.724458</td>\n",
       "      <td>0.315385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.168317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.738170</td>\n",
       "      <td>0.186275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.740506</td>\n",
       "      <td>0.247706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        False      True\n",
       "          Agreement                    \n",
       "precision 0.25       0.943548  0.200000\n",
       "          0.50       0.983193  0.093923\n",
       "          0.75       0.991525  0.103825\n",
       "          1.00       1.000000  0.141361\n",
       "recall    0.25       0.587940  0.745455\n",
       "          0.50       0.587940  0.809524\n",
       "          0.75       0.587940  0.904762\n",
       "          1.00       0.587940  1.000000\n",
       "f1-score  0.25       0.724458  0.315385\n",
       "          0.50       0.735849  0.168317\n",
       "          0.75       0.738170  0.186275\n",
       "          1.00       0.740506  0.247706"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['Agreement'] = 1.0\n",
    "df_p75['Agreement'] = 0.75\n",
    "df_p5['Agreement'] = 0.5\n",
    "df_p25['Agreement'] = 0.25\n",
    "df = pd.concat((df_1,df_p75,df_p5,df_p25)).drop('support',axis=1)\n",
    "df.loc[['False','True']].pivot(columns='Agreement').transpose()#.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9bcc993f-9633-4369-84fb-532ecc7ec0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & False & True \\\\\n",
      " & Agreement &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{4}{*}{precision} & 0.250000 & 0.940000 & 0.200000 \\\\\n",
      " & 0.500000 & 0.980000 & 0.090000 \\\\\n",
      " & 0.750000 & 0.990000 & 0.100000 \\\\\n",
      " & 1.000000 & 1.000000 & 0.140000 \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{4}{*}{recall} & 0.250000 & 0.590000 & 0.750000 \\\\\n",
      " & 0.500000 & 0.590000 & 0.810000 \\\\\n",
      " & 0.750000 & 0.590000 & 0.900000 \\\\\n",
      " & 1.000000 & 0.590000 & 1.000000 \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{4}{*}{f1-score} & 0.250000 & 0.720000 & 0.320000 \\\\\n",
      " & 0.500000 & 0.740000 & 0.170000 \\\\\n",
      " & 0.750000 & 0.740000 & 0.190000 \\\\\n",
      " & 1.000000 & 0.740000 & 0.250000 \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((np.round(df.loc[['False','True']].pivot(columns='Agreement').transpose()*100)/100).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ee34b-9bf1-456d-936c-e8e38239bd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacey_pipeline",
   "language": "python",
   "name": "spacey_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
